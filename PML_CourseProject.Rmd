Course Project Practical Machine Learning
=========================================

```{r, echo=FALSE}
xmsg <- sprintf("date and time: %s and version used: %s", Sys.time(), R.Version()$version.string)
```

Synopsis
--------
This prediction project was done on `r xmsg` by Lucho Farje. Using data which has been generated by devices such as Nike, FuelBand, FitBit and Jawbone Up about personal activity and self movements which were attached in their body of different persons. The goal using this dataset is to find patterns using machine learning to build a prediction model. The data to be used is coming from accelerometers on the belt, forearm, arm and dumbell of 6 participants which were asked to perform barbell lifts correctly and incorrectly in five different ways.

Setting Global Environment
--------------------------
This prediction analysis needs some packages in order to be processed. The **caret** package is important for this prediction model as well as another support packages which makes the entire analysis process much easier to perform.
An important hint in this process is to highlight that in this step it's being initialized the seed variable and creating a clusters of cores for this computer. 

```{r cache=FALSE,echo=TRUE,results='hide'}
library(caret)
library(randomForest)
library(rattle)
library(pROC)

library(rpart)

library(parallel)
library(doParallel)

library(ggplot2)
library(reshape2)

library(xtable)
#using parallel clusters for the cores of this machine/server
cluster.cores<-makeCluster(detectCores()-1)
registerDoParallel(cluster.cores)
#Initialize seed
day.of.begin.project<-"2015-01-16"
seed.number<-as.numeric(as.Date(day.of.begin.project))
set.seed(seed.number)
```

Download and Load Datasets
--------------------------
In this step the data will be downloaded and loaded into variables in order to be filtered and pre-processed for applying the prediction model.

```{r, cache=TRUE, echo=TRUE}
if (!file.exists("./data/pml-testing.csv"))
  { download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", "./data/pml-testing.csv") }

if (!file.exists("./data/pml-training.csv"))
  { download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", "./data/pml-training.csv") }

data.training<-read.csv("./data/pml-training.csv", na.strings=c("NA",""), stringsAsFactors=FALSE)
data.testing<-read.csv("./data/pml-testing.csv", na.strings=c("NA",""), stringsAsFactors=FALSE)
```

Data Pre-Processing
-------------------
It's important to apply a function in order to filter the features which might contain any missing data, in other words, there are many variables in the dataset and it's imperative to remove any with NA's values or empty strings. It's also being removed all columns that are not included in the prediction model.
It's important to point that it's not necessary to **create a data partition** for these datasets because there are already two set of files one for training and one for testing.
Finally, it's also considered to show a histogram for each type of accelerometer used in differents parts of the body. This is done by a function and help of **ggplot2** packages which was previously loaded.

```{r, cache=TRUE, echo=TRUE, fig.width=7, fig.height=6}
filteringdata<-function(dataset)
  {
  keepdata<-!sapply(dataset, function(x) any(is.na(x)))
  dataset<-dataset[,keepdata]
  keepdata<-!sapply(dataset, function(x) any(x==""))
  dataset<-dataset[,keepdata]
  
  removingcol<-c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window", "num_window")
  doremove<-which(colnames(dataset) %in% removingcol)
  dataset<-dataset[,-doremove]
  return(dataset)
  }
data.training<-filteringdata(data.training)
data.training$classe<-factor(data.training$classe)
data.testing<-filteringdata(data.testing)

#head(data.training)
#head(data.testing)

histogramxGroup <- function (data, regex) {
  col <- grep(regex, names(data))
  col <- c(col, which(names(data) == "classe"))
  n <- nrow(data)
  DMelted <- melt(data[, col, ][ , ], id.vars=c("classe"))
  ggplot(DMelted, aes(x=classe, y=value)) +
    #geom_violin(aes(color=classe, fill=classe), alpha=1/2) +
    geom_jitter(aes(color=classe, fill=classe), alpha=1/10) +
    facet_wrap(~ variable, scale="free_y") +
    scale_color_brewer(type="qual", palette=1) +
    scale_fill_brewer(type="qual", palette=1) +
    labs(x="", y="") +
    theme(legend.position="none")
}

histogramxGroup(data.training,"belt")
histogramxGroup(data.training,"[^(fore)]arm")
histogramxGroup(data.training,"dumbbell")
histogramxGroup(data.training,"forearm")

```

Train and Evaluate The Prediction Model
---------------------------------------
For training the dataset will be used **random forest** and **SVM (radial kernel)** algorithms. The goal is to get an accuracy of greather than 0.930. For processing the dataset faster, it will be used parallel clusters which were defined in the first section and will be stopped as a final step in this section because of size of the data. For testing the model it won't be needed to parallelize cores. 
The cross-validation is being done 5 times with help of the parameter number in the **trainControl** function.
It's also shown a cross-validation accuracy table for these two models where the model which uses **random forest** reach more higher accuracy than other model.
The prediction models are applied to the **hat** variables and then the confussion Matrix is generated. 
Finally, it will be calculated variable importance for each model and then it's written that **randon forest** algorithm gives a better accuracy of **99,57%**

```{r cache=TRUE, echo=TRUE, fig.width=15, fig.height=15}
controlPM<-trainControl(method="cv", number=5, allowParallel=TRUE, verboseIter=TRUE)
model1<-train(classe~., data=data.training,method="rf",trControl=controlPM)
model2<-train(classe~., data=data.training,method="svmRadial",trControl=controlPM)

accuracy.table<-data.frame(Model=c("Random Forest", "SVM (radial)"), Accuracy=c(round(max(head(model1$results)$Accuracy),3), round(max(head(model2$results)$Accuracy),3)))

#require(rpart.plot)
#build.dt <- rpart(classe ~ ., data=data.training, method="class")
#build.dt$Accuracy
#fancyRpartPlot(build.dt)

accuracy.table

hatm1<-predict(model1, data.training)
hatm2<-predict(model2, data.training)

#hatm1tmp<-predict(model1, data.training, type="class") #either raw or prob

confusionMatrix(hatm1, data.training$classe)
confusionMatrix(hatm2, data.training$classe)

varImp(model1)
require(pROC)
varImp(model2)

model1$finalModel
model2$finalModel

stopCluster(cluster.cores)
```

Applying Prediction Mode On Data Test
-------------------------------------
Once the prediction model has been calculated so it's time to apply it on the test data set.

```{r cache=TRUE, echo=TRUE}
hatTD<-predict(model1, data.testing)
#confusionMatrix(hatTD, data.test$classe)
data.testing<-cbind(hatTD, data.testing)
subset(data.testing, select=names(data.testing)[grep("belt|[^(fore)]arm|dumbbell|forearm", names(data.testing), invert=TRUE)])
```

Submission results to Coursera
------------------------------
The last step is to generate files for each row/case of the test data set. It's being used a coursera code to achieve that.

```{r cache=TRUE, echo=TRUE}
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("./answers/problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}
pml_write_files(hatTD)
```